{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ATOC5860 Application Lab #6 - supervised machine learning\n",
    "### Coded by Eleanor Middlemas (Jupiter, formerly University of Colorado, elmiddlemas at gmail.com)\n",
    "### Additional code/commenting by Jennifer Kay (University of Colorado) \n",
    "### Last updated April 6, 2022\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1: Read in the Data into a pandas dataframe and Look At It"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In this notebook, we will use supervised machine learning models to:*\n",
    "\n",
    "**1) Predict the likelihood of rainfall given certain atmospheric conditions.**\n",
    "After prepping the data, we will build and train four machine learning models to make the predictions: Logistic regression, Random Forest, Singular vector machines/classifier, Neural Network\n",
    "\n",
    "**2) Determine which variable (\"feature\") is the best predictor of rainfall, i.e., \"feature importance\"**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>temp_F</th>\n",
       "      <th>RH</th>\n",
       "      <th>dewtemp_F</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>windgust</th>\n",
       "      <th>windgust_dir</th>\n",
       "      <th>pres_Hg</th>\n",
       "      <th>SOLIN_Wm2</th>\n",
       "      <th>Prec_inches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>234</td>\n",
       "      <td>3.9</td>\n",
       "      <td>224</td>\n",
       "      <td>851.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42370</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>5.4</td>\n",
       "      <td>74.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>299</td>\n",
       "      <td>7.1</td>\n",
       "      <td>302</td>\n",
       "      <td>850.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>42370</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>6.4</td>\n",
       "      <td>73.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>200</td>\n",
       "      <td>7.0</td>\n",
       "      <td>301</td>\n",
       "      <td>849.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42370</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>309</td>\n",
       "      <td>6.1</td>\n",
       "      <td>349</td>\n",
       "      <td>850.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42370</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>3.7</td>\n",
       "      <td>76.9</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>346</td>\n",
       "      <td>5.3</td>\n",
       "      <td>255</td>\n",
       "      <td>848.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>42735</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>22.3</td>\n",
       "      <td>74.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>221</td>\n",
       "      <td>3.3</td>\n",
       "      <td>202</td>\n",
       "      <td>833.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>42735</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>20.3</td>\n",
       "      <td>80.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>279</td>\n",
       "      <td>2.9</td>\n",
       "      <td>279</td>\n",
       "      <td>833.45</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>42735</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>19.9</td>\n",
       "      <td>81.1</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>197</td>\n",
       "      <td>2.5</td>\n",
       "      <td>279</td>\n",
       "      <td>833.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>42735</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>17.8</td>\n",
       "      <td>82.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>353</td>\n",
       "      <td>4.8</td>\n",
       "      <td>352</td>\n",
       "      <td>832.78</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8783</th>\n",
       "      <td>42735</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>16.3</td>\n",
       "      <td>84.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191</td>\n",
       "      <td>4.9</td>\n",
       "      <td>353</td>\n",
       "      <td>832.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8784 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        day      hour  temp_F    RH  dewtemp_F  wind_mph  wind_dir  windgust  \\\n",
       "0     42370  0.000000     7.0  72.2       -0.1       1.2       234       3.9   \n",
       "1     42370  0.041667     5.4  74.3       -1.0       3.4       299       7.1   \n",
       "2     42370  0.083333     6.4  73.8       -0.2       2.8       200       7.0   \n",
       "3     42370  0.125000     3.0  73.5       -3.6       2.9       309       6.1   \n",
       "4     42370  0.166667     3.7  76.9       -1.9       3.1       346       5.3   \n",
       "...     ...       ...     ...   ...        ...       ...       ...       ...   \n",
       "8779  42735  0.791667    22.3  74.3       15.4       0.9       221       3.3   \n",
       "8780  42735  0.833333    20.3  80.4       15.3       0.6       279       2.9   \n",
       "8781  42735  0.875000    19.9  81.1       15.1       0.5       197       2.5   \n",
       "8782  42735  0.916667    17.8  82.8       13.5       2.0       353       4.8   \n",
       "8783  42735  0.958333    16.3  84.1       12.4       1.0       191       4.9   \n",
       "\n",
       "      windgust_dir  pres_Hg  SOLIN_Wm2  Prec_inches  \n",
       "0              224   851.30        0.0          0.0  \n",
       "1              302   850.82        0.0          0.0  \n",
       "2              301   849.83        0.0          0.0  \n",
       "3              349   850.69        0.0          0.0  \n",
       "4              255   848.24        0.0          0.0  \n",
       "...            ...      ...        ...          ...  \n",
       "8779           202   833.32        0.0          0.0  \n",
       "8780           279   833.45        0.1          0.0  \n",
       "8781           279   833.01        0.1          0.0  \n",
       "8782           352   832.78        0.1          0.0  \n",
       "8783           353   832.62        0.0          0.0  \n",
       "\n",
       "[8784 rows x 12 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data\n",
    "df = pd.read_csv(\"christman_2016.csv\")\n",
    "# preview data (also through df.head() & df.tail())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "366"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.day.nunique() ## Print the answer to: How many days are in this dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Optional: transform the day column into a readable date. Run this ONCE.\n",
    "df['day'] = [datetime.date.fromordinal(day+693594) for day in df['day']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['RH','dewtemp_F'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2: Data and Function Preparation\n",
    "\n",
    "Data preparation is a huge part of building Machine Learning model \"pipelines\". Carefully think through building & training a Machine Learning model before you run it. There are a few statistical \"gotchas\" that may result in your model being biased, inaccurate, or not suitable for the problem at hand.  Address these 6 questions!\n",
    "\n",
    "**Q1: What exactly are we trying to predict? A value, an outcome, a category?** Define your predictors and predictand. Relate these to your hypothesis or overarching question. In our case, our predictand is the likelihood of precipitation. We will build models to predict the likelihood that it's currently precipitating, given current atmospheric conditions.\n",
    "\n",
    "**Q2: Do you have any missing data? If so, how will you handle them?** Keep in mind, decreasing the number of input observations may bias your model. Using the Christman dataset, we have no missing data.\n",
    "\n",
    "**Q3: Do you have any categorical or non-numeric variables or features?** If so, you must figure out how to encode them into numbers. Luckily, in the geosciences, we rarely run into this problem.\n",
    "\n",
    "**Q4: How will we validate our model?** Typically, people split their existing data into training data and testing data, or perform \"cross-validation\" or a \"test-train split\". That is, we will \"hold out\" some data and call it our \"testing data\", while using the rest of the data to train our model (i.e., \"training data\"). Once our model is trained, we will evaluate its performance with the holdout testing data. Note: This could be problematic if there is limited data.\n",
    "\n",
    "**Q5: Do your features have the same variance?** You need to consider this to ensure your model doesn't overly depend on one variable with large variance. This step is called \"feature scaling\". Features of the same size also speed up the Gradient Descent algorithm.\n",
    "\n",
    "**Q6: If classification is the goal, are there the same number of observations for each feature and outcome? If not, how will you rebalance?** Here, the Christman dataset has same number of observations (8784) for each feature. But, times with no precipitation are way more common than times with precipitation. To deal with this issue, we will oversample the observations associated with precip so that the two outcomes (or \"classes\") are equal. Note: It's important that feature scaling or normalization is performed before any rebalancing so that the qualitative statistics (mean, stddev, etc) remain the same.\n",
    "\n",
    "**Q7: Which metrics are appropriate for assessing your model?** Consider the bias-variance trade-off, and whether having false positives or false negatives is more impactful. In our case, predicting no rain when there is rain (false negative) is probably more frustrating and potentially more impactful than the other way around (a false positive)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1. What exactly are you trying to predict?**\n",
    "\n",
    "First, split data into predictor & predictands. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create a new feature that indicates whether precipitation occurred. Perform this step ONCE.\n",
    "#print(df.columns) # print if you need to see what is the variable called that indicates precipitation amount?\n",
    "df['prec_occur'] = np.array(df.Prec_inches!=0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_F</th>\n",
       "      <th>RH</th>\n",
       "      <th>dewtemp_F</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>windgust</th>\n",
       "      <th>windgust_dir</th>\n",
       "      <th>pres_Hg</th>\n",
       "      <th>SOLIN_Wm2</th>\n",
       "      <th>prec_occur</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>72.2</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>234</td>\n",
       "      <td>3.9</td>\n",
       "      <td>224</td>\n",
       "      <td>851.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.4</td>\n",
       "      <td>74.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>299</td>\n",
       "      <td>7.1</td>\n",
       "      <td>302</td>\n",
       "      <td>850.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.4</td>\n",
       "      <td>73.8</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>200</td>\n",
       "      <td>7.0</td>\n",
       "      <td>301</td>\n",
       "      <td>849.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>73.5</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>309</td>\n",
       "      <td>6.1</td>\n",
       "      <td>349</td>\n",
       "      <td>850.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.7</td>\n",
       "      <td>76.9</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>346</td>\n",
       "      <td>5.3</td>\n",
       "      <td>255</td>\n",
       "      <td>848.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8779</th>\n",
       "      <td>22.3</td>\n",
       "      <td>74.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>221</td>\n",
       "      <td>3.3</td>\n",
       "      <td>202</td>\n",
       "      <td>833.32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8780</th>\n",
       "      <td>20.3</td>\n",
       "      <td>80.4</td>\n",
       "      <td>15.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>279</td>\n",
       "      <td>2.9</td>\n",
       "      <td>279</td>\n",
       "      <td>833.45</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>19.9</td>\n",
       "      <td>81.1</td>\n",
       "      <td>15.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>197</td>\n",
       "      <td>2.5</td>\n",
       "      <td>279</td>\n",
       "      <td>833.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8782</th>\n",
       "      <td>17.8</td>\n",
       "      <td>82.8</td>\n",
       "      <td>13.5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>353</td>\n",
       "      <td>4.8</td>\n",
       "      <td>352</td>\n",
       "      <td>832.78</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8783</th>\n",
       "      <td>16.3</td>\n",
       "      <td>84.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191</td>\n",
       "      <td>4.9</td>\n",
       "      <td>353</td>\n",
       "      <td>832.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8784 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      temp_F    RH  dewtemp_F  wind_mph  wind_dir  windgust  windgust_dir  \\\n",
       "0        7.0  72.2       -0.1       1.2       234       3.9           224   \n",
       "1        5.4  74.3       -1.0       3.4       299       7.1           302   \n",
       "2        6.4  73.8       -0.2       2.8       200       7.0           301   \n",
       "3        3.0  73.5       -3.6       2.9       309       6.1           349   \n",
       "4        3.7  76.9       -1.9       3.1       346       5.3           255   \n",
       "...      ...   ...        ...       ...       ...       ...           ...   \n",
       "8779    22.3  74.3       15.4       0.9       221       3.3           202   \n",
       "8780    20.3  80.4       15.3       0.6       279       2.9           279   \n",
       "8781    19.9  81.1       15.1       0.5       197       2.5           279   \n",
       "8782    17.8  82.8       13.5       2.0       353       4.8           352   \n",
       "8783    16.3  84.1       12.4       1.0       191       4.9           353   \n",
       "\n",
       "      pres_Hg  SOLIN_Wm2  prec_occur  \n",
       "0      851.30        0.0           0  \n",
       "1      850.82        0.0           0  \n",
       "2      849.83        0.0           0  \n",
       "3      850.69        0.0           0  \n",
       "4      848.24        0.0           0  \n",
       "...       ...        ...         ...  \n",
       "8779   833.32        0.0           0  \n",
       "8780   833.45        0.1           0  \n",
       "8781   833.01        0.1           0  \n",
       "8782   832.78        0.1           0  \n",
       "8783   832.62        0.0           0  \n",
       "\n",
       "[8784 rows x 10 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Next, select the data that will be predictors.\n",
    "predictors = df.copy(deep=True)  # here, we use \"deep = True\" so that changes to predictors won't be made to the df.\n",
    "\n",
    "#Next, we drop some variables that shouldn't be used to predict whether or not there is rain.\n",
    "predictors = df.drop(['day','hour','Prec_inches'],axis=1) \n",
    "predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Great, that worked. Now I will assign everything but \"prec\" to be the predictor array \"x\", \n",
    "## and prec will be the predictand vector \"y\".\n",
    "\n",
    "x = predictors.drop('prec_occur',axis=1)\n",
    "y = predictors.prec_occur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2 & Q3 do not need to be addressed in our dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4. How will you validate your model?**\n",
    "\n",
    "We will perform a test-train split to validate our trained model. This step must be performed before each time the model is trained to ensure we are not baking in any bias among the models we train. That also means the following two steps must also be performed prior to training each model as well. For this reason, we write functions to call \n",
    "easily before each model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_holdout_data(x, y, verbose):\n",
    "    \"\"\"Perform a 80/20 test-train split (80% of data is training, 20% is testing). Split is randomized with each call.\"\"\"\n",
    "    random_state = randint(0,1000)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20, random_state=random_state)\n",
    "    if verbose==True:\n",
    "        print(\"Prior to scaling and rebalacing...\")\n",
    "        print(\"Shape of training predictors: \"+str(np.shape(x_train)))\n",
    "        print(\"Shape of testing predictors: \"+str(np.shape(x_test)))\n",
    "        print(\"Shape of training predictands: \"+str(np.shape(y_train)))\n",
    "        print(\"Shape of testing predictands: \"+str(np.shape(y_test)))\n",
    "        print(\" \")\n",
    "    return x_train, x_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5. Do your features have the same variance?**\n",
    "\n",
    "We must normalize the features. In machine learning this is called Feature Scaling\". We do this so that the features with the largest variance are note weighted more heavily than those with less variance. Note: If our predictand wasn't binary, then we would normalize it as well.\n",
    "\n",
    "We'll keep the data as a pandas dataframe rather than converting it to a numpy array beforehand. The \"fit_transform\" function outputs a numpy array, but we will convert back to a dataframe so that re-balancing the dataset is easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(x_train, x_test):\n",
    "    \"\"\"\n",
    "    Scale training data so that model reaches optimized weights much faster. \n",
    "    \n",
    "    *All data that enters the model should use the same scaling used to scale the training data.*\n",
    "    Thus, we also perform scaling on testing data for validation later. \n",
    "    Additionally, we return the scaler used to scale any other future input data.\n",
    "    \"\"\"\n",
    "    \n",
    "    scaler = preprocessing.MinMaxScaler() # normalize \n",
    "    x_train_scaled = pd.DataFrame(data=scaler.fit_transform(x_train),index=x_train.index,columns=x_train.columns) \n",
    "    x_test_scaled = pd.DataFrame(data=scaler.transform(x_test),index=x_test.index,columns=x_test.columns)\n",
    "    \n",
    "    return scaler, x_train_scaled, x_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6. Are there the same number of observations for each outcome or class?**\n",
    "Luckily, we have the same number of observations for each feature (8784). But do we have the same number of outcomes for our predictand?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8501\n",
       "1     283\n",
       "Name: prec_occur, dtype: int64"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['prec_occur'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Definitely not. The outcomes we are trying to predict are extremely unbalanced. Non-precip hours occur 30x more than precip hours. This class imbalance may bias the model because precip hours are underrepresented, which means the model won't have as many instances of precip hours to learn to distinguish precip hours from non-precip hours.\n",
    "\n",
    "There are a number of out-of-the-box functions that resample data very precisely. The one I use below simply randomly oversamples the existing precipitating observation data to balance the dataset.\n",
    "\n",
    "Note: This function should be called on both training and testing data separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_data(x,y,verbose):\n",
    "    \"\"\"Resample data ensure model is not biased towards a particular outcome of precip or no precip.\"\"\"\n",
    "    # Combine again to one dataframe to ensure both the predictor and predictand are resampled from the same \n",
    "    # observations based on predictand outcomes. \n",
    "    dataset = pd.concat([x, y],axis=1)\n",
    "\n",
    "    # Separating classes\n",
    "    raining = dataset[dataset['prec_occur'] == 1]\n",
    "    not_raining = dataset[dataset['prec_occur'] == 0]\n",
    "\n",
    "    random_state = randint(0,1000)\n",
    "    oversample = resample(raining, \n",
    "                           replace=True, \n",
    "                           n_samples=len(not_raining), #set the number of samples to equal the number of the majority class\n",
    "                           random_state=random_state)\n",
    "\n",
    "    # Returning to new training set\n",
    "    oversample_dataset = pd.concat([not_raining, oversample])\n",
    "\n",
    "    # reseparate oversampled data into X and y sets\n",
    "    x_bal = oversample_dataset.drop(['prec_occur'], axis=1)\n",
    "    y_bal = oversample_dataset['prec_occur']\n",
    "\n",
    "    if verbose==True:\n",
    "        print(\"After scaling and rebalacing...\")\n",
    "        print(\"Shape of predictors: \"+str(np.shape(x_bal)))\n",
    "        print(\"Shape of predictands: \"+str(np.shape(y_bal)))\n",
    "        print(\" \")\n",
    "    \n",
    "    return x_bal, y_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For ease, let's put the data prep code from questions 1-6 into a pipeline.  In other words we will write a single function to accomplish everything we have done so far in this notebook.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataprep_pipeline(x, y, verbose):\n",
    "    \"\"\" Combines all the functions defined above so that the user only has to \n",
    "    call one function to do all data pre-processing. \"\"\"\n",
    "    # verbose=True prints the shapes of input & output data\n",
    "\n",
    "    # split into training & testing data\n",
    "    x_train, x_test, y_train, y_test = define_holdout_data(x, y, verbose) \n",
    "\n",
    "    # perform feature scaling\n",
    "    scaler, x_train_scaled, x_test_scaled = scale_data(x_train, x_test)\n",
    "\n",
    "    # rebalance according to outcomes (i.e., the number of precipitating \n",
    "    # observations & non-precipitating outcomes should be equal)\n",
    "    if verbose==True:\n",
    "        print(\"for training data... \")\n",
    "    x_train_bal, y_train_bal = balance_data(x_train_scaled, y_train, verbose)\n",
    "    if verbose==True:\n",
    "        print(\"for testing data... \")\n",
    "    x_test_bal, y_test_bal = balance_data(x_test_scaled, y_test, verbose)\n",
    "    \n",
    "    return x_train_bal, y_train_bal, x_test_bal, y_test_bal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7. What are the appropriate metrics for assessing your model?**\n",
    "These metrics will be used to evaluate each model after training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some commonly-used metrics for assessing the value of a given Machine Learning model.\n",
    "\n",
    "\"**True Positive (TP)**\" Is the number of times the model predicts a positive when the observation is actually positive. In our case, the model predicts that its raining when it is actually raining.<br>\n",
    "\"**False Positive (FP)**\" The number of times the model guesses that it's raining when it's not actually raining.<br>\n",
    "The same applies to **True Negatives (TN)** (correctly predicting that it's not raining) and **False Negatives (FN)** (predicting no rain when it's actually raining).\n",
    "\n",
    "\n",
    " - **Precision = TP/(TP + FP)**: The proportion of predicted precipitating events that are actually precipitating.\n",
    " - **Accuracy = (TP + TN)/(total)**: The proportion of precipitating hours or non-precipitating hours that are correctly predicted by the model.\n",
    " - **Recall = TP/(TP + FN)**: The proportion of precipitating hours that are correctly predicted by the model.<br>\n",
    "<br>\n",
    "Other important metrics that we aren't going to look at today:\n",
    " - **F1**: a way to capture how well the model predicts the hours that it's actually precipitating.\n",
    " - **ROC/AUC**: how well the model separates precipitating hours from non-precipitating hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! conda install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print rounded metrics for each model.\n",
    "def bin_metrics(x, y):\n",
    "    \"\"\"Prints accuracy and recall metrics for evaluating \n",
    "    classification predictions.\"\"\"\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(x, y)\n",
    "    recall = metrics.recall_score(x, y)\n",
    "\n",
    "    print('Accuracy:', round(accuracy, 4))\n",
    "    print('Recall:', round(recall, 4))\n",
    "    \n",
    "    return accuracy, recall\n",
    "\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_cm(x, y):\n",
    "    \"\"\"Plots the confusion matrix to visualize true \n",
    "    & false positives & negatives\"\"\"\n",
    "    cm = confusion_matrix(x, y)\n",
    "    df_cm = pd.DataFrame(cm, columns=np.unique(x), index = np.unique(x))\n",
    "    df_cm.index.name = 'Actual'\n",
    "    df_cm.columns.name = 'Predicted'\n",
    "    sns.heatmap(df_cm, cmap=\"Blues\", annot=True,annot_kws={\"size\": 25}, fmt='g')# font size\n",
    "    plt.ylim([0, 2])\n",
    "    plt.xticks([0.5, 1.5], ['Negatives','Positives'])\n",
    "    plt.yticks([0.5, 1.5], ['Negatives','Positives'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way we can evaluate the models is to compare precipitation likelihood given the same set of atmospheric conditions.  First, let's choose some observation in the pre-scaled dataset shows that it's raining, and then find the corresponding scaled observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_atmos_conditions_precip(index='rand'):\n",
    "    \"\"\"\n",
    "    Function returns atmospheric conditions in a dataframe as well as the scaled\n",
    "    conditions in a numpy array so that they output a prediction in the model.\n",
    "    \n",
    "    If no input is passed, the function will randomly generate an in index to \n",
    "    choose from those observations in some training data with precipitation. \n",
    "    Otherwise, an integer index between 0 and 200 should be passed.\n",
    "    \"\"\"\n",
    "    # First, perform a test-train split\n",
    "    x_train, x_test, y_train, _ = define_holdout_data(x, y, verbose=False) \n",
    "\n",
    "    # perform feature scaling\n",
    "    _, x_train_scaled, _ = scale_data(x_train, x_test)\n",
    "\n",
    "    # this is what will go into the model to output a prediction\n",
    "    if index=='rand':\n",
    "        index = randint(0,len(y_train[y_train==1].index)) \n",
    "    precipindex = y_train[y_train==1].index.values[index]\n",
    "    testpredictor = x_train_scaled.loc[precipindex] \n",
    "    \n",
    "    return df.iloc[precipindex], testpredictor    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3: Train & Compare Machine Learning Models\n",
    "Each section below goes through building and training a ML model. In each section, there are a few steps for each model \"pipeline\":\n",
    "1. __Randomly perform a test-train split, feature scaling, and resample data to ensure outcomes are balanced__. \n",
    "2. __Train your model__.\n",
    "3. __Assess model metrics with testing and training data__. We begin by first assessing each model's performance by calculating the metrics defined above on the *testing* or *holdout* data; the key here is that the model has never seen this data. <br>__If applicable, tune your model.__ This means choosing new *hyperparameters*, retraining the model, and then reassessing the same model metrics to see if the model yields better results.\n",
    "3. __Check for model overfitting__. We will also check to see if the model is overfitting by comparing metrics of the testing data to that of the training data. In short, the training data should not be outperforming the testing data.\n",
    "4. __Actually make a prediction with a single observation__. Predicted precipitation probability provides a sanity test for us to make sure the model isn't way off base. It allows us to see for ourselves: given X meteorological conditions and our own understanding of meteorology, would rain seem likely? Is the model actually doing something realistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior to scaling and rebalacing...\n",
      "Shape of training predictors: (7027, 9)\n",
      "Shape of testing predictors: (1757, 9)\n",
      "Shape of training predictands: (7027,)\n",
      "Shape of testing predictands: (1757,)\n",
      " \n",
      "for training data... \n",
      "After scaling and rebalacing...\n",
      "Shape of predictors: (13598, 9)\n",
      "Shape of predictands: (13598,)\n",
      " \n",
      "for testing data... \n",
      "After scaling and rebalacing...\n",
      "Shape of predictors: (3404, 9)\n",
      "Shape of predictands: (3404,)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## 1. Perform a test-train split, perform feature scaling, and the rebalance our dataset.\n",
    "x_train_bal, y_train_bal, x_test_bal, y_test_bal = dataprep_pipeline(x, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Train the Logistic Regression model\n",
    "\n",
    "# initialize the model\n",
    "lr = LogisticRegression(solver='lbfgs') \n",
    "# we choose this particular solver because we're not regularizing or penalizing certain features\n",
    "\n",
    "# fit the model to scaled & balanced training data. Side note: this is where *Gradient Descent* occurs.\n",
    "lr.fit(x_train_bal, y_train_bal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8622\n",
      "Recall: 0.9031\n"
     ]
    }
   ],
   "source": [
    "## 3. Assess Logistic Regression's performance using testing data\n",
    "\n",
    "##Now that we've \"trained\" our model, we make predictions using data that the \n",
    "## model has never seen before (i.e., our holdout testing data) to see how it performs.\n",
    "\n",
    "y_pred = lr.predict(x_test_bal)\n",
    "\n",
    "# Call functions defined above to calculate metrics & plot a confusion matrix based on\n",
    "# how well model simulates testing data\n",
    "#plot_cm(y_test_bal, y_pred);\n",
    "lr_acc, lr_rec = bin_metrics(y_test_bal, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy tells is the percent of correct predictions, whether precipitating or not. The Logistic Regression model, without any additional tuning, can correctly predict whether it's precipitating or not given a set of present atmospheric conditions around 84% of the time.\n",
    "\n",
    "False Positives are less harmful than False Negatives. Thus, along with accuracy, we should also try to maximize recall.\n",
    "\n",
    "A very important aspect of tuning machine learning model is to ensure the model isn't overfitting or underfitting:\n",
    "An overfit model means the model is fit very well to the training data, but fails to generalize predictions outside the training dataset. A symptom of overfitting is that the models' training accuracy is much better than the testing accuracy. Overfitting can happen more easily in more complex models, like neural networks. To alleviate overfitting, one needs to reduce variance, through feature regularization, lowering model complexity, or performing k-folds cross-validation.\n",
    "\n",
    "Before you dive too deeply into ML and in your own time, I suggest watching this (https://www.youtube.com/watch?v=EuBBz3bI-aA) 6-minute StatQuest YouTube video to develop more intuition for model error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics:\n",
      "Accuracy: 0.8412\n",
      "Recall: 0.8685\n",
      " \n",
      "Testing metrics:\n",
      "Accuracy: 0.8622\n",
      "Recall: 0.9031\n"
     ]
    }
   ],
   "source": [
    "##4. Check to see if the Logistic Regression model is overfitting (or underfitting)\n",
    "#Remember:\n",
    "#testing metrics > training metrics = underfitting, model is too simple\n",
    "#testing metrics < training metrics = overfitting, model is too complex\n",
    "\n",
    "# Compare testing data metrics to data training metrics.\n",
    "print(\"Training metrics:\")\n",
    "pred_train= lr.predict(x_train_bal) \n",
    "bin_metrics(y_train_bal,pred_train);\n",
    "\n",
    "# As a reminder, display testing metrics:\n",
    "print(\" \")\n",
    "print(\"Testing metrics:\")\n",
    "bin_metrics(y_test_bal, y_pred);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_F          0.401055\n",
      "RH              0.869718\n",
      "dewtemp_F       0.532915\n",
      "wind_mph        0.294118\n",
      "wind_dir        0.966574\n",
      "windgust        0.247041\n",
      "windgust_dir    0.863510\n",
      "pres_Hg         0.812239\n",
      "SOLIN_Wm2       0.043284\n",
      "Name: 2575, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## 5. Make a prediction with the Logistic Regression model\n",
    "#First, we randomly choose some atmospheric conditions using the function defined above. This will be the atmospheric conditions we use for all models we build.\n",
    "\n",
    "origvals, testpredictor = rand_atmos_conditions_precip()\n",
    "#print(origvals) # observation from original dataframe\n",
    "print(testpredictor) # scaled observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meteorological conditions are: \n",
      "day             2016-04-17\n",
      "hour              0.291667\n",
      "temp_F                31.3\n",
      "RH                    81.6\n",
      "dewtemp_F             26.3\n",
      "wind_mph              11.5\n",
      "wind_dir               347\n",
      "windgust              16.7\n",
      "windgust_dir           310\n",
      "pres_Hg             848.29\n",
      "SOLIN_Wm2             43.5\n",
      "Prec_inches           0.02\n",
      "prec_occur               1\n",
      "Name: 2575, dtype: object\n",
      " \n",
      "There is a 83.58% chance of precipitation given those meteorological conditions.\n"
     ]
    }
   ],
   "source": [
    "# prediction output is in the format [probability no rain, probability rain]\n",
    "lr_prediction = lr.predict_proba(np.array(testpredictor).reshape(1, -1))[0][1]*100 \n",
    "print(\"The meteorological conditions are: \")\n",
    "print(origvals)\n",
    "print(\" \")\n",
    "print(\"There is a {0:.{digits}f}% chance of precipitation given those meteorological conditions.\".format(lr_prediction, digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Random Forest\n",
    "\n",
    "To understand random forests, one must first understand a [decision tree](https://scikit-learn.org/stable/modules/tree.html#tree). A decision tree is intuitive: it is essentially a flowchart to point to an outcome based on \"decisions\" for each feature. A Random Forest is an ensemble of decision trees that are randomly constructed based on the features of the dataset and number of decisions. Trees are constructed by randomly choosing a feature to \"seed\" each tree, and then making rules or associations with other features to lead to the specified outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "##1. Perform a test-train split, perform feature scaling, and the rebalance our dataset.\n",
    "## Perform a train-test split for cross-validation, perform feature scaling, and \n",
    "## rebalance each testing & training dataset.\n",
    "\n",
    "x_train_bal, y_train_bal, x_test_bal, y_test_bal = dataprep_pipeline(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimators is 10\n",
      "depth is 2\n",
      "depth is 10\n",
      "depth is 100\n",
      "Random Forest took 0.49694204330444336 seconds.\n",
      "Number of estimators is 50\n",
      "depth is 2\n",
      "depth is 10\n",
      "depth is 100\n",
      "Random Forest took 1.5188899040222168 seconds.\n",
      "Number of estimators is 500\n",
      "depth is 2\n",
      "depth is 10\n",
      "depth is 100\n",
      "Random Forest took 14.910454988479614 seconds.\n"
     ]
    }
   ],
   "source": [
    "##2. Train (and tuning) the Random Forest model\n",
    "\n",
    "##Choosing hyperparameters: There are many hyperparameters one can decide upon when tuning the \n",
    "## Random Forest classifier. The two we will adjust are: 1) The number of estimators or \"trees\" in the forest\n",
    "## 2) The depth of the tree, or how many \"decisions\" are made until convergence is reached.\n",
    "\n",
    "acc_scores = []\n",
    "rec_scores = []\n",
    "\n",
    "num_est = [10, 50, 500] # number of trees\n",
    "depth = [2, 10, 100] # number of decisions\n",
    "for i in num_est:\n",
    "    start = time.time()\n",
    "    print(\"Number of estimators is \"+str(i))\n",
    "\n",
    "    for k in depth:\n",
    "        print(\"depth is \"+str(k))\n",
    "        forest = RandomForestClassifier(n_estimators=i, max_depth=k)\n",
    "        forest.fit(x_train_bal, y_train_bal)\n",
    "        \n",
    "        # cross validate & evaluate metrics based on testing data\n",
    "        pred_test= forest.predict(x_test_bal)\n",
    "        acc_val = metrics.accuracy_score(y_test_bal, pred_test)\n",
    "        acc_scores.append(acc_val)\n",
    "        rec_val = metrics.recall_score(y_test_bal, pred_test)\n",
    "        rec_scores.append(rec_val)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Random Forest took \"+str(end-start)+\" seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy (black): 0.7926\n",
      "Max Recall (blue): 0.6918\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### visualize the recall and accuracy scores for the different hyperparameter choices\n",
    "plt.plot(acc_scores, marker='o', color='black',label='accuracy')\n",
    "plt.plot(rec_scores, marker='o', color='blue',label='recall')\n",
    "plt.xlabel('Hyperparameter Choice')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "print(\"Max Accuracy (black):\", round(max(acc_scores), 4))\n",
    "print(\"Max Recall (blue):\", round(max(rec_scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which choice of hyperparameters should we pick? Choosing the right hyperparameters for this model requires revisiting which metrics are most important to our question. For this problem, we want to maximize both recall and accuracy.\n",
    "\n",
    "Let's go with the parameters corresponding to x=0 (Looks good for both accuracy and recall!) but try other hyperparameters too (if you have time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(n_estimators=10, max_depth=2);\n",
    "forest.fit(x_train_bal, y_train_bal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7796\n",
      "Recall: 0.6918\n"
     ]
    }
   ],
   "source": [
    "## 3. Assess the Random Forest's performance using testing data\n",
    "##Once again, we will use our testing data to make an initial evaluation of how the model is doing.\n",
    "\n",
    "pred_test= forest.predict(x_test_bal)\n",
    "\n",
    "# Call functions defined above to calculate metrics & plot a confusion matrix based on\n",
    "# how well model simulates testing data\n",
    "forest_acc, forest_rec = bin_metrics(y_test_bal, pred_test)\n",
    "# plot_cm(y_test_bal, pred_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics:\n",
      "Accuracy: 0.7889\n",
      "Recall: 0.7112\n",
      " \n",
      "Testing metrics:\n",
      "Accuracy: 0.7796\n",
      "Recall: 0.6918\n"
     ]
    }
   ],
   "source": [
    "## 4. Check to see if the Random Forest is overfitting (or underfitting)\n",
    "#Remember:\n",
    "#testing metrics > training metrics = underfitting, model is too simple\n",
    "#testing metrics < training metrics = overfitting, model is too complex\n",
    "\n",
    "# Compare testing data metrics to data training metrics.\n",
    "print(\"Training metrics:\")\n",
    "rf_pred_train= forest.predict(x_train_bal) \n",
    "bin_metrics(y_train_bal,rf_pred_train);\n",
    "\n",
    "# As a reminder, display testing metrics:\n",
    "print(\" \")\n",
    "print(\"Testing metrics:\")\n",
    "bin_metrics(y_test_bal, pred_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW - the random forest model was not an improvement over the logistical regression model.\n",
    "\n",
    "Random forests seldom overfit, but if they do, one should try increasing the number of trees, or decreasing the amount of data used to construct each tree. See scikit-learn's Random Forest Classifier webpage (https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) for information on more hyperparameters one can tune to address overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meteorological conditions are: \n",
      "day             2016-04-17\n",
      "hour              0.291667\n",
      "temp_F                31.3\n",
      "RH                    81.6\n",
      "dewtemp_F             26.3\n",
      "wind_mph              11.5\n",
      "wind_dir               347\n",
      "windgust              16.7\n",
      "windgust_dir           310\n",
      "pres_Hg             848.29\n",
      "SOLIN_Wm2             43.5\n",
      "Prec_inches           0.02\n",
      "prec_occur               1\n",
      "Name: 2575, dtype: object\n",
      " \n",
      "There is a 83.89% chance of precipitation given those meteorological conditions.\n"
     ]
    }
   ],
   "source": [
    "##5. Make a prediction with the Random Forest\n",
    "\n",
    "# prediction output is in the format [probability no rain, probability rain]\n",
    "forest_prediction = forest.predict_proba(np.array(testpredictor).reshape(1, -1))[0][1]*100 \n",
    "print(\"The meteorological conditions are: \")\n",
    "print(origvals)\n",
    "print(\" \")\n",
    "print(\"There is a {0:.{digits}f}% chance of precipitation given those meteorological conditions.\".format(forest_prediction, digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Support Vector Machines (SVMs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVMs divide observations into classes based on maximizing the distance between a \"kernel\" (basically a dividing function) and the elements of each feature/class/variable on a plane. Because the relationships between atmospheric variables and precipitation are inherently non-linear, we will choose a non-linear, \"RBF\" kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Perform a test-train split, perform feature scaling, and the rebalance our dataset.\n",
    "x_train_bal, y_train_bal, x_test_bal, y_test_bal = dataprep_pipeline(x, y, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing hyperparameters\n",
    "In the case of SVMs, we can tune \"C\", the regularization parameter. Regularization) penalizes higher-order coefficients during training (i.e., Gradient Descent). Regularization is a way to reduce a model's complexity and address overfitting.\n",
    "\n",
    "In SVMs, the lower the regularization parameter C, the higher the penalty. We are unsure what the C value should be. Thus, we train the model three times, each with a different value of C to see what the best value should be. I highly suggest learning more on regularization if you choose to pursue ML methods on your own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C is... 0.01\n",
      "Took 20.551054000854492 seconds to train.\n",
      "C is... 1\n",
      "Took 10.445567846298218 seconds to train.\n",
      "C is... 100\n",
      "Took 9.986533880233765 seconds to train.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samo2402/opt/anaconda3/envs/intro2ml_environment/lib/python3.7/site-packages/sklearn/svm/_base.py:249: ConvergenceWarning: Solver terminated early (max_iter=20000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "## 2. Train (and tune) the SVM (Note: this cell takes ~1 minute to run)\n",
    "\n",
    "acc_scores = []\n",
    "rec_scores = []\n",
    "\n",
    "C_range = [0.01, 1, 100]\n",
    "for i in C_range:\n",
    "    start = time.time()\n",
    "    print(\"C is... \"+str(i))\n",
    "    svmclassifier = svm.SVC(C=i, kernel='rbf', gamma='scale', max_iter=20000, probability=True)\n",
    "    svmclassifier.fit(x_train_bal, y_train_bal)\n",
    "    \n",
    "    # Save model metrics in order to choose best hyperparameter\n",
    "    pred_test= svmclassifier.predict(x_test_bal)\n",
    "    acc_val = metrics.accuracy_score(y_test_bal, pred_test)\n",
    "    acc_scores.append(acc_val)\n",
    "    rec_val = metrics.recall_score(y_test_bal, pred_test)\n",
    "    rec_scores.append(rec_val)\n",
    "\n",
    "    end = time.time()\n",
    "    print(\"Took \"+str(end-start)+\" seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy (black): 0.8754\n",
      "Max Recall (blue): 0.8622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(C_range, acc_scores, marker='o', color='black',label='accuracy')\n",
    "plt.plot(C_range, rec_scores, marker='o', color='blue',label='recall')\n",
    "plt.xlabel('Hyperparameter Choice')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "\n",
    "print(\"Max Accuracy (black):\", round(max(acc_scores), 4))\n",
    "print(\"Max Recall (blue):\", round(max(rec_scores), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM with C=1, i.e., a medium weight penalty, results in a balance among accuracy, precision, and recall.\n",
    "We will train our final model with this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SVM classifier & fit to training data\n",
    "svmclassifier = svm.SVC(C=1, kernel='rbf', gamma='scale', max_iter=20000, probability=True)\n",
    "svmclassifier.fit(x_train_bal, y_train_bal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_F</th>\n",
       "      <th>RH</th>\n",
       "      <th>dewtemp_F</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>windgust</th>\n",
       "      <th>windgust_dir</th>\n",
       "      <th>pres_Hg</th>\n",
       "      <th>SOLIN_Wm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1718</th>\n",
       "      <td>0.706245</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.429467</td>\n",
       "      <td>0.135193</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.275915</td>\n",
       "      <td>0.986072</td>\n",
       "      <td>0.353032</td>\n",
       "      <td>0.649453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6933</th>\n",
       "      <td>0.613896</td>\n",
       "      <td>0.354460</td>\n",
       "      <td>0.573668</td>\n",
       "      <td>0.152361</td>\n",
       "      <td>0.855153</td>\n",
       "      <td>0.147866</td>\n",
       "      <td>0.899721</td>\n",
       "      <td>0.536485</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5065</th>\n",
       "      <td>0.689534</td>\n",
       "      <td>0.786385</td>\n",
       "      <td>0.841170</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.927577</td>\n",
       "      <td>0.132622</td>\n",
       "      <td>0.913649</td>\n",
       "      <td>0.495118</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5223</th>\n",
       "      <td>0.723835</td>\n",
       "      <td>0.526995</td>\n",
       "      <td>0.779519</td>\n",
       "      <td>0.103004</td>\n",
       "      <td>0.543175</td>\n",
       "      <td>0.155488</td>\n",
       "      <td>0.348189</td>\n",
       "      <td>0.548818</td>\n",
       "      <td>0.194826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>0.587511</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.684431</td>\n",
       "      <td>0.296137</td>\n",
       "      <td>0.022284</td>\n",
       "      <td>0.397866</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.522354</td>\n",
       "      <td>0.138507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8181</th>\n",
       "      <td>0.283201</td>\n",
       "      <td>0.924883</td>\n",
       "      <td>0.409613</td>\n",
       "      <td>0.107296</td>\n",
       "      <td>0.264624</td>\n",
       "      <td>0.185976</td>\n",
       "      <td>0.289694</td>\n",
       "      <td>0.527749</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3092</th>\n",
       "      <td>0.521548</td>\n",
       "      <td>0.890845</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.738162</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.785515</td>\n",
       "      <td>0.357657</td>\n",
       "      <td>0.000398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.383465</td>\n",
       "      <td>0.982394</td>\n",
       "      <td>0.541275</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>0.495427</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>0.373587</td>\n",
       "      <td>0.009751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.383465</td>\n",
       "      <td>0.982394</td>\n",
       "      <td>0.541275</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.891365</td>\n",
       "      <td>0.495427</td>\n",
       "      <td>0.924791</td>\n",
       "      <td>0.373587</td>\n",
       "      <td>0.009751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>0.715919</td>\n",
       "      <td>0.423709</td>\n",
       "      <td>0.719958</td>\n",
       "      <td>0.133047</td>\n",
       "      <td>0.359331</td>\n",
       "      <td>0.245427</td>\n",
       "      <td>0.607242</td>\n",
       "      <td>0.504111</td>\n",
       "      <td>0.386667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3396 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temp_F        RH  dewtemp_F  wind_mph  wind_dir  windgust  \\\n",
       "1718  0.706245  0.083333   0.429467  0.135193  0.038997  0.275915   \n",
       "6933  0.613896  0.354460   0.573668  0.152361  0.855153  0.147866   \n",
       "5065  0.689534  0.786385   0.841170  0.124464  0.927577  0.132622   \n",
       "5223  0.723835  0.526995   0.779519  0.103004  0.543175  0.155488   \n",
       "2416  0.587511  0.666667   0.684431  0.296137  0.022284  0.397866   \n",
       "...        ...       ...        ...       ...       ...       ...   \n",
       "8181  0.283201  0.924883   0.409613  0.107296  0.264624  0.185976   \n",
       "3092  0.521548  0.890845   0.678161  0.111588  0.738162  0.125000   \n",
       "1976  0.383465  0.982394   0.541275  0.502146  0.891365  0.495427   \n",
       "1976  0.383465  0.982394   0.541275  0.502146  0.891365  0.495427   \n",
       "5726  0.715919  0.423709   0.719958  0.133047  0.359331  0.245427   \n",
       "\n",
       "      windgust_dir   pres_Hg  SOLIN_Wm2  \n",
       "1718      0.986072  0.353032   0.649453  \n",
       "6933      0.899721  0.536485   0.000000  \n",
       "5065      0.913649  0.495118   0.000000  \n",
       "5223      0.348189  0.548818   0.194826  \n",
       "2416      0.013928  0.522354   0.138507  \n",
       "...            ...       ...        ...  \n",
       "8181      0.289694  0.527749   0.000100  \n",
       "3092      0.785515  0.357657   0.000398  \n",
       "1976      0.924791  0.373587   0.009751  \n",
       "1976      0.924791  0.373587   0.009751  \n",
       "5726      0.607242  0.504111   0.386667  \n",
       "\n",
       "[3396 rows x 9 columns]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8754\n",
      "Recall: 0.8622\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## 3. Assess SVM performance using testing data\n",
    "\n",
    "pred_test= svmclassifier.predict(x_test_bal)\n",
    "\n",
    "# Call functions defined above to calculate metrics & plot a confusion matrix based on\n",
    "# how well model simulates testing data\n",
    "svm_acc, svm_rec = bin_metrics(y_test_bal, pred_test)\n",
    "plot_cm(y_test_bal, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WOW: using a non-linear Singular Vector Machine instead of a Logistic Regressor increased the recall and accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training metrics:\n",
      "Accuracy: 0.9183\n",
      "Recall: 0.9422\n",
      " \n",
      "Testing metrics:\n",
      "Accuracy: 0.8754\n",
      "Recall: 0.8622\n"
     ]
    }
   ],
   "source": [
    "## 4. Check to see if the SVM is overfitting (or underfitting)\n",
    "#Remember:\n",
    "#testing metrics > training metrics = underfitting, model is too simple\n",
    "#testing metrics < training metrics = overfitting, model is too complex\n",
    "\n",
    "# Compare testing data metrics to data training metrics.\n",
    "print(\"Training metrics:\")\n",
    "svm_pred_train= svmclassifier.predict(x_train_bal) \n",
    "bin_metrics(y_train_bal,svm_pred_train);\n",
    "\n",
    "# As a reminder, display testing metrics:\n",
    "print(\" \")\n",
    "print(\"Testing metrics:\")\n",
    "bin_metrics(y_test_bal, pred_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can address overfitting in an SVM by changing the kernel to a simpler kernel, or tuning the regularization parameter C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "temp_F          0.401055\n",
       "RH              0.869718\n",
       "dewtemp_F       0.532915\n",
       "wind_mph        0.294118\n",
       "wind_dir        0.966574\n",
       "windgust        0.247041\n",
       "windgust_dir    0.863510\n",
       "pres_Hg         0.812239\n",
       "SOLIN_Wm2       0.043284\n",
       "Name: 2575, dtype: float64"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testpredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The meteorological conditions are: \n",
      "day             2016-04-17\n",
      "hour              0.291667\n",
      "temp_F                31.3\n",
      "RH                    81.6\n",
      "dewtemp_F             26.3\n",
      "wind_mph              11.5\n",
      "wind_dir               347\n",
      "windgust              16.7\n",
      "windgust_dir           310\n",
      "pres_Hg             848.29\n",
      "SOLIN_Wm2             43.5\n",
      "Prec_inches           0.02\n",
      "prec_occur               1\n",
      "Name: 2575, dtype: object\n",
      " \n",
      "There is a 99.35% chance of precipitation given those meteorological conditions.\n"
     ]
    }
   ],
   "source": [
    "## 5. Make a prediction with the SVM\n",
    "\n",
    "# prediction output is in the format [probability no rain, probability rain]\n",
    "svm_prediction = svmclassifier.predict_proba(np.array(testpredictor).reshape(1, -1))[0][1]*100 \n",
    "print(\"The meteorological conditions are: \")\n",
    "print(origvals)\n",
    "print(\" \")\n",
    "print(\"There is a {0:.{digits}f}% chance of precipitation given those meteorological conditions.\".format(svm_prediction, digits=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4: Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there is a TON of information online about Neural Networks. Eleanor Recommends:\n",
    "1) This three-part series of youtube videos (totaling about an hour in length) https://www.youtube.com/watch?v=aircAruvnKk. \n",
    "\n",
    "2) machinelearningmastery.com In fact, the model below is based off of this blog post (https://machinelearningmastery.com/binary-classification-tutorial-with-the-keras-deep-learning-library/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install tensorflow\n",
    "# ! pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras #! pip install tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Perform a test-train split, perform feature scaling, and the rebalance our dataset.\n",
    "x_train_bal, y_train_bal, x_test_bal, y_test_bal = dataprep_pipeline(x, y, verbose=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. Train (and build and compile) the Neural Network\n",
    "## There are lots of hyperparameters here. Please read the comments to guide you in playing with them later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_F</th>\n",
       "      <th>RH</th>\n",
       "      <th>dewtemp_F</th>\n",
       "      <th>wind_mph</th>\n",
       "      <th>wind_dir</th>\n",
       "      <th>windgust</th>\n",
       "      <th>windgust_dir</th>\n",
       "      <th>pres_Hg</th>\n",
       "      <th>SOLIN_Wm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4232</th>\n",
       "      <td>0.751979</td>\n",
       "      <td>0.377934</td>\n",
       "      <td>0.733542</td>\n",
       "      <td>0.169528</td>\n",
       "      <td>0.440111</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.406685</td>\n",
       "      <td>0.595478</td>\n",
       "      <td>0.450249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5243</th>\n",
       "      <td>0.696570</td>\n",
       "      <td>0.685446</td>\n",
       "      <td>0.815047</td>\n",
       "      <td>0.047210</td>\n",
       "      <td>0.200557</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.403900</td>\n",
       "      <td>0.540428</td>\n",
       "      <td>0.186169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6011</th>\n",
       "      <td>0.719437</td>\n",
       "      <td>0.592723</td>\n",
       "      <td>0.803553</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>0.270195</td>\n",
       "      <td>0.121302</td>\n",
       "      <td>0.339833</td>\n",
       "      <td>0.679282</td>\n",
       "      <td>0.349652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2486</th>\n",
       "      <td>0.704485</td>\n",
       "      <td>0.198357</td>\n",
       "      <td>0.554859</td>\n",
       "      <td>0.143777</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.258876</td>\n",
       "      <td>0.963788</td>\n",
       "      <td>0.627918</td>\n",
       "      <td>0.249154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3204</th>\n",
       "      <td>0.663149</td>\n",
       "      <td>0.427230</td>\n",
       "      <td>0.664577</td>\n",
       "      <td>0.182403</td>\n",
       "      <td>0.331476</td>\n",
       "      <td>0.251479</td>\n",
       "      <td>0.155989</td>\n",
       "      <td>0.784959</td>\n",
       "      <td>0.914428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>0.580475</td>\n",
       "      <td>0.793427</td>\n",
       "      <td>0.717868</td>\n",
       "      <td>0.221030</td>\n",
       "      <td>0.050139</td>\n",
       "      <td>0.304734</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.770951</td>\n",
       "      <td>0.024776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>0.401935</td>\n",
       "      <td>0.969484</td>\n",
       "      <td>0.560084</td>\n",
       "      <td>0.248927</td>\n",
       "      <td>0.885794</td>\n",
       "      <td>0.264793</td>\n",
       "      <td>0.849582</td>\n",
       "      <td>0.756205</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0.369393</td>\n",
       "      <td>0.990610</td>\n",
       "      <td>0.525601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.938719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.454411</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>0.517150</td>\n",
       "      <td>0.950704</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.068670</td>\n",
       "      <td>0.306407</td>\n",
       "      <td>0.090237</td>\n",
       "      <td>0.384401</td>\n",
       "      <td>0.797739</td>\n",
       "      <td>0.010149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>0.359719</td>\n",
       "      <td>0.929577</td>\n",
       "      <td>0.500522</td>\n",
       "      <td>0.109442</td>\n",
       "      <td>0.362117</td>\n",
       "      <td>0.190828</td>\n",
       "      <td>0.228412</td>\n",
       "      <td>0.284345</td>\n",
       "      <td>0.184279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13600 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        temp_F        RH  dewtemp_F  wind_mph  wind_dir  windgust  \\\n",
       "4232  0.751979  0.377934   0.733542  0.169528  0.440111  0.192308   \n",
       "5243  0.696570  0.685446   0.815047  0.047210  0.200557  0.076923   \n",
       "6011  0.719437  0.592723   0.803553  0.068670  0.270195  0.121302   \n",
       "2486  0.704485  0.198357   0.554859  0.143777  0.041783  0.258876   \n",
       "3204  0.663149  0.427230   0.664577  0.182403  0.331476  0.251479   \n",
       "...        ...       ...        ...       ...       ...       ...   \n",
       "5562  0.580475  0.793427   0.717868  0.221030  0.050139  0.304734   \n",
       "2567  0.401935  0.969484   0.560084  0.248927  0.885794  0.264793   \n",
       "172   0.369393  0.990610   0.525601  0.000000  0.938719  0.000000   \n",
       "6151  0.517150  0.950704   0.689655  0.068670  0.306407  0.090237   \n",
       "758   0.359719  0.929577   0.500522  0.109442  0.362117  0.190828   \n",
       "\n",
       "      windgust_dir   pres_Hg  SOLIN_Wm2  \n",
       "4232      0.406685  0.595478   0.450249  \n",
       "5243      0.403900  0.540428   0.186169  \n",
       "6011      0.339833  0.679282   0.349652  \n",
       "2486      0.963788  0.627918   0.249154  \n",
       "3204      0.155989  0.784959   0.914428  \n",
       "...            ...       ...        ...  \n",
       "5562      0.019499  0.770951   0.024776  \n",
       "2567      0.849582  0.756205   0.000000  \n",
       "172       0.025070  0.454411   0.000199  \n",
       "6151      0.384401  0.797739   0.010149  \n",
       "758       0.228412  0.284345   0.184279  \n",
       "\n",
       "[13600 rows x 9 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_bal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Build a very simple Neural Network and Compile\n",
    "number_inputs = len(x_train_bal.columns)\n",
    "\n",
    "# create model\n",
    "nn = Sequential()\n",
    "nn.add(Dense(number_inputs, input_dim=number_inputs, activation='relu'))\n",
    "\n",
    "# Try uncommenting this to address overfitting\n",
    "# from keras.regularizers import l2\n",
    "# reg = l2(0.001)\n",
    "# nn.add(Dense(number_inputs, activation='relu',bias_regularizer=reg,activity_regularizer=reg))\n",
    "\n",
    "# try commenting out one and then the other\n",
    "nn.add(Dense(1, activation='sigmoid'))\n",
    "#nn.addDense(1, activation='softmax'))\n",
    "\n",
    "# Compile model \n",
    "# Also try changing the learning rate.\n",
    "learning_rate = 0.001 # only used in the SGD optimizer.\n",
    "\n",
    "# Also try commenting out one & then the other. \n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy']) \n",
    "#nn.compile(loss='binary_crossentropy', optimizer=keras.optimizers.SGD(lr=learning_rate), metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "567/567 - 1s - loss: 0.6573 - accuracy: 0.6379 - val_loss: 0.6221 - val_accuracy: 0.7454\n",
      "Epoch 2/100\n",
      "567/567 - 0s - loss: 0.5767 - accuracy: 0.7741 - val_loss: 0.5723 - val_accuracy: 0.7366\n",
      "Epoch 3/100\n",
      "567/567 - 1s - loss: 0.5238 - accuracy: 0.7777 - val_loss: 0.5392 - val_accuracy: 0.7466\n",
      "Epoch 4/100\n",
      "567/567 - 0s - loss: 0.4867 - accuracy: 0.7968 - val_loss: 0.5141 - val_accuracy: 0.7604\n",
      "Epoch 5/100\n",
      "567/567 - 0s - loss: 0.4600 - accuracy: 0.8102 - val_loss: 0.4964 - val_accuracy: 0.7722\n",
      "Epoch 6/100\n",
      "567/567 - 0s - loss: 0.4405 - accuracy: 0.8196 - val_loss: 0.4875 - val_accuracy: 0.7798\n",
      "Epoch 7/100\n",
      "567/567 - 0s - loss: 0.4268 - accuracy: 0.8233 - val_loss: 0.4825 - val_accuracy: 0.7828\n",
      "Epoch 8/100\n",
      "567/567 - 0s - loss: 0.4161 - accuracy: 0.8277 - val_loss: 0.4741 - val_accuracy: 0.7822\n",
      "Epoch 9/100\n",
      "567/567 - 0s - loss: 0.4072 - accuracy: 0.8335 - val_loss: 0.4765 - val_accuracy: 0.7934\n",
      "Epoch 10/100\n",
      "567/567 - 0s - loss: 0.3993 - accuracy: 0.8352 - val_loss: 0.4724 - val_accuracy: 0.8042\n",
      "Epoch 11/100\n",
      "567/567 - 0s - loss: 0.3926 - accuracy: 0.8374 - val_loss: 0.4637 - val_accuracy: 0.8101\n",
      "Epoch 12/100\n",
      "567/567 - 0s - loss: 0.3866 - accuracy: 0.8404 - val_loss: 0.4605 - val_accuracy: 0.8119\n",
      "Epoch 13/100\n",
      "567/567 - 0s - loss: 0.3811 - accuracy: 0.8429 - val_loss: 0.4534 - val_accuracy: 0.8122\n",
      "Epoch 14/100\n",
      "567/567 - 0s - loss: 0.3752 - accuracy: 0.8444 - val_loss: 0.4439 - val_accuracy: 0.8116\n",
      "Epoch 15/100\n",
      "567/567 - 0s - loss: 0.3680 - accuracy: 0.8489 - val_loss: 0.4303 - val_accuracy: 0.8119\n",
      "Epoch 16/100\n",
      "567/567 - 0s - loss: 0.3586 - accuracy: 0.8546 - val_loss: 0.4193 - val_accuracy: 0.8157\n",
      "Epoch 17/100\n",
      "567/567 - 0s - loss: 0.3512 - accuracy: 0.8582 - val_loss: 0.4120 - val_accuracy: 0.8163\n",
      "Epoch 18/100\n",
      "567/567 - 0s - loss: 0.3455 - accuracy: 0.8589 - val_loss: 0.4044 - val_accuracy: 0.8125\n",
      "Epoch 19/100\n",
      "567/567 - 0s - loss: 0.3412 - accuracy: 0.8596 - val_loss: 0.4105 - val_accuracy: 0.8292\n",
      "Epoch 20/100\n",
      "567/567 - 0s - loss: 0.3378 - accuracy: 0.8600 - val_loss: 0.4041 - val_accuracy: 0.8257\n",
      "Epoch 21/100\n",
      "567/567 - 0s - loss: 0.3354 - accuracy: 0.8596 - val_loss: 0.3996 - val_accuracy: 0.8242\n",
      "Epoch 22/100\n",
      "567/567 - 0s - loss: 0.3328 - accuracy: 0.8604 - val_loss: 0.3935 - val_accuracy: 0.8122\n",
      "Epoch 23/100\n",
      "567/567 - 0s - loss: 0.3312 - accuracy: 0.8612 - val_loss: 0.3939 - val_accuracy: 0.8166\n",
      "Epoch 24/100\n",
      "567/567 - 0s - loss: 0.3295 - accuracy: 0.8616 - val_loss: 0.3981 - val_accuracy: 0.8269\n",
      "Epoch 25/100\n",
      "567/567 - 0s - loss: 0.3284 - accuracy: 0.8621 - val_loss: 0.3915 - val_accuracy: 0.8216\n",
      "Epoch 26/100\n",
      "567/567 - 0s - loss: 0.3276 - accuracy: 0.8618 - val_loss: 0.3974 - val_accuracy: 0.8275\n",
      "Epoch 27/100\n",
      "567/567 - 0s - loss: 0.3262 - accuracy: 0.8629 - val_loss: 0.3918 - val_accuracy: 0.8204\n",
      "Epoch 28/100\n",
      "567/567 - 0s - loss: 0.3252 - accuracy: 0.8632 - val_loss: 0.3944 - val_accuracy: 0.8233\n",
      "Epoch 29/100\n",
      "567/567 - 0s - loss: 0.3247 - accuracy: 0.8633 - val_loss: 0.3910 - val_accuracy: 0.8248\n",
      "Epoch 30/100\n",
      "567/567 - 0s - loss: 0.3238 - accuracy: 0.8629 - val_loss: 0.3913 - val_accuracy: 0.8301\n",
      "Epoch 31/100\n",
      "567/567 - 0s - loss: 0.3234 - accuracy: 0.8621 - val_loss: 0.3915 - val_accuracy: 0.8289\n",
      "Epoch 32/100\n",
      "567/567 - 0s - loss: 0.3222 - accuracy: 0.8646 - val_loss: 0.3871 - val_accuracy: 0.8248\n",
      "Epoch 33/100\n",
      "567/567 - 0s - loss: 0.3227 - accuracy: 0.8621 - val_loss: 0.3908 - val_accuracy: 0.8316\n",
      "Epoch 34/100\n",
      "567/567 - 0s - loss: 0.3208 - accuracy: 0.8646 - val_loss: 0.3907 - val_accuracy: 0.8295\n",
      "Epoch 35/100\n",
      "567/567 - 0s - loss: 0.3203 - accuracy: 0.8640 - val_loss: 0.3913 - val_accuracy: 0.8322\n",
      "Epoch 36/100\n",
      "567/567 - 0s - loss: 0.3195 - accuracy: 0.8638 - val_loss: 0.3869 - val_accuracy: 0.8260\n",
      "Epoch 37/100\n",
      "567/567 - 1s - loss: 0.3185 - accuracy: 0.8624 - val_loss: 0.3878 - val_accuracy: 0.8269\n",
      "Epoch 38/100\n",
      "567/567 - 0s - loss: 0.3178 - accuracy: 0.8649 - val_loss: 0.3913 - val_accuracy: 0.8319\n",
      "Epoch 39/100\n",
      "567/567 - 1s - loss: 0.3166 - accuracy: 0.8642 - val_loss: 0.3887 - val_accuracy: 0.8283\n",
      "Epoch 40/100\n",
      "567/567 - 1s - loss: 0.3161 - accuracy: 0.8639 - val_loss: 0.3870 - val_accuracy: 0.8248\n",
      "Epoch 41/100\n",
      "567/567 - 0s - loss: 0.3150 - accuracy: 0.8649 - val_loss: 0.3896 - val_accuracy: 0.8239\n",
      "Epoch 42/100\n",
      "567/567 - 1s - loss: 0.3143 - accuracy: 0.8655 - val_loss: 0.3912 - val_accuracy: 0.8289\n",
      "Epoch 43/100\n",
      "567/567 - 1s - loss: 0.3135 - accuracy: 0.8646 - val_loss: 0.3896 - val_accuracy: 0.8225\n",
      "Epoch 44/100\n",
      "567/567 - 1s - loss: 0.3126 - accuracy: 0.8657 - val_loss: 0.3990 - val_accuracy: 0.8354\n",
      "Epoch 45/100\n",
      "567/567 - 1s - loss: 0.3118 - accuracy: 0.8649 - val_loss: 0.3993 - val_accuracy: 0.8336\n",
      "Epoch 46/100\n",
      "567/567 - 1s - loss: 0.3112 - accuracy: 0.8660 - val_loss: 0.3973 - val_accuracy: 0.8316\n",
      "Epoch 47/100\n"
     ]
    }
   ],
   "source": [
    "### Actually training the model\n",
    "\n",
    "batch_size = 24 # The number of samples the network sees before it backpropagates (batch size) # 24 & 32 yield accuracy = 87%\n",
    "epochs = 100 # The number of times the network will loop through the entire dataset (epochs)\n",
    "shuffle = True # Set whether to shuffle the training data so the model doesn't see it sequentially \n",
    "verbose = 2 # Set whether the model will output information when trained (0 = no output; 2 = output accuracy every epoch)\n",
    "\n",
    "# Train the neural network!\n",
    "start = time.time()\n",
    "\n",
    "history = nn.fit(x_train_bal, y_train_bal, validation_data=(x_test_bal, y_test_bal), \n",
    "          batch_size=batch_size, epochs=epochs, shuffle=shuffle, verbose=verbose)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Neural Network took \"+str(end-start)+\" seconds to train.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy & loss with epochs\n",
    "#Neural networks train in epochs. During each epoch, the model trains by sweeping over each layer, \n",
    "#adjusting weights based on their resulting errors, through processes called forward propagation and backpropagation. \n",
    "#By plotting the model accuracy & loss which each epoch, we can visualize how the model error evolves with training.\n",
    "\n",
    "figure, axes = plt.subplots(nrows=2,ncols=1)\n",
    "figure.tight_layout(pad=3.0)\n",
    "\n",
    "# plot accuracy during training\n",
    "plt.subplot(211)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='test')\n",
    "plt.legend();\n",
    "\n",
    "# plot loss during training\n",
    "plt.subplot(212)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel(\"Epoch\");\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##3. Assess Neural Network's performance using testing data\n",
    "## Though the accuracy is pictured above, additionally quantify recall on testing data with the \n",
    "## same functions used previously to remain consistent\n",
    "\n",
    "pred_test= (nn.predict(x_test_bal)>0.5).astype(\"int32\")\n",
    "nn_acc, nn_rec = bin_metrics(y_test_bal, pred_test)\n",
    "plot_cm(y_test_bal, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. Check to see if the Neural Network is overfitting (or underfitting)\n",
    "#Remember:\n",
    "#testing metrics > training metrics = underfitting, model is too simple\n",
    "#testing metrics < training metrics = overfitting, model is too complex\n",
    "\n",
    "#Note: Neural networks can easily overfit because they are complex and can fit to the training data extremely well, \n",
    "# Overfitting prevents neural networks from generalizing to other data (like the testing data).\n",
    "\n",
    "# Compare testing data metrics to data training metrics.\n",
    "print(\"Training metrics:\")\n",
    "nn_pred_train= (nn.predict(x_train_bal)>0.5).astype(\"int32\")\n",
    "bin_metrics(y_train_bal,nn_pred_train);\n",
    "\n",
    "# As a reminder, display testing metrics:\n",
    "print(\" \")\n",
    "print(\"Testing metrics:\")\n",
    "bin_metrics(y_test_bal, pred_test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. Make a prediction with the Neural Network\n",
    "\n",
    "# prediction output is in the format [probability no rain, probability rain]\n",
    "nn_prediction = nn.predict(np.array(testpredictor).reshape(1, -1))[0][0]*100\n",
    "print(\"The meteorological conditions are: \")\n",
    "print(origvals)\n",
    "print(\"There is a {0:.{digits}f}% chance of precipitation given those meteorological conditions.\".format(nn_prediction, digits=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARY: Compare all Four Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_metrics = pd.DataFrame({'Metrics':['Accuracy','Recall','Prediction example'],\n",
    "     'Logistic Regression':[lr_acc, lr_rec, lr_prediction],\n",
    "    'Random Forest':[forest_acc, forest_rec, forest_prediction],\n",
    "    'Singular Vector Machine':[svm_acc, svm_rec, svm_prediction],\n",
    "    'Neural Network':[nn_acc, nn_rec, nn_prediction]})\n",
    "model_metrics = model_metrics.set_index('Metrics')\n",
    "model_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 4: Assess Feature Importance\n",
    "\n",
    "Note: Feature Importance is not possible with non-linear Singular Vector Machines because the data is transformed by the kernel into another space that is unrelated to the input space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature importance in Logistical Regression Model\n",
    "\n",
    "pd.DataFrame(abs(lr.coef_[0]),\n",
    "             index = x.columns,\n",
    "             columns=['importance']).sort_values('importance',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature importance in Random Forest Model\n",
    "\n",
    "pd.DataFrame(forest.feature_importances_,\n",
    "                                   index = x.columns, \n",
    "                                   columns=['importance']).sort_values('importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feature importance in Neural Network\n",
    "\n",
    "cols = x.columns.values\n",
    "nn_featimportance = []\n",
    "for var in cols:\n",
    "    # create a vector corresponding to a 1 where the feature is located:\n",
    "    inputvector = np.array((cols==var).astype(int).reshape(1, -1))\n",
    "    nn_featimportance.append(nn.predict(inputvector)[0][0]*100)\n",
    "\n",
    "pd.DataFrame( nn_featimportance,\n",
    "             index = x.columns,\n",
    "             columns=['importance']).sort_values('importance',ascending=False)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
